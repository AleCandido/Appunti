% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../Appunti.tex

\section{Introduzione}

In seguito si considera un modello di \textit{gas perfetto} per illustrare alcune delle affermazioni generali fatte.

\begin{defn}[Gas perfetto]
	Un \textit{gas perfetto} è un insieme di particelle (o, generalizzando, strutture elementari) \textit{non interagenti}.
\end{defn}

Per rendere il sistema \textit{non integrabile}, e quindi \textit{ergodico}, si deve però assumere che ci sia qualche modo per far scambiare impulso fra le particelle, e quindi farle interagire. Si può pensare ad un interazione mediata dalle pareti della scatola che contiene il gas.

\paragraph{Osservabili macroscopiche} A livello microscopico il sistema è quindi caratterizzato dall'Hamiltoniano di singola particella, e non c'è altro da aggiungere. Si vuole però caratterizzare il sistema nel suo insieme attraverso delle \textit{osservabili macroscopiche} e trovare le relazioni fra esse: si vuole trovare \textit{l'equazione di stato} del sistema complessivo.

Si vuole quindi indagare a livello microscopico l'origine di concetti macroscopici quali: \textit{entropia}, \textit{irreversibilità} e \textit{equilibrio}.

\subsection{Principi della Meccanica Statistica}
Per colmare il salto che separa la descrizione \textit{microscopica} dalle proprietà \textit{macroscopiche} del sistema la Meccanica Statistica di equilibrio pone essenzialmente due principi:

\begin{description}
	\item[Perdita di memoria:] all'equilibrio, che si suppone sempre raggiunto da un sistema dopo un tempo sufficientemente lungo (rispetto alle scale temporali delle interazioni microscopiche), il \textit{macrostato} del sistema è indipendente dalle condizioni iniziali.
	\item[Equiprobabilità a priori:] all'equilibrio ogni possibile \textit{microstato} è equiprobabile. La disponibilità di un data microstato dipende dai vincoli che deve soddisfare il sistema (es.: conservazione dell'energia).
\end{description}

\subsubsection{Equilibrio}

Si è parlato di \textit{equilibrio}, senza specificare cosa si intenda per esso. Non è una questione banale, ma a questo livello se ne può dare una definizione approssimativa.

\begin{defn}[Equilibrio]
	\label{def:eq}
	Si dice che un sistema macroscopico è all'\textit{equilibrio} quando tutte le osservabili macroscopiche sono \textit{stazionarie}, cioè non evolvono nel tempo.
\end{defn}

La \cref{def:eq} è approssimativa in quanto si considereranno in seguito trasformazioni fra stati di equilibrio.
\`E però una buona definizione se si specifica che la scala temporale su cui va valutata la stazionarietà è \textit{mesoscopica}: per tempo \textit{microscopici} il sistema evolve secondo la dinamica data dalle singole interazioni, mentre a livello \textit{macroscopico} l'evoluzione è data dalla trasformazione considerata.

Infatti per mantenere la condizione di equilibrio la scala microscopica e quella macroscopica sono separate da diversi ordini di grandezza, per cui è possibile la verifica della stazionarietà delle osservabili su scale intermedie, che vanno però considerate come nettamente distinte dalle altre (si può pensare a tre stati diversi, analogamente all'elettronica digitale in confronto alla natura analogica dei segnali).

\paragraph{Sulla natura dei principi fisici} \`E importante tenere presente che le due assunzioni fatte sono \textit{principi}, quindi non necessariamente verificati per ogni sistema fisico, ma sperimentalmente veri per un buon numero di sistemi e assunti per tutti gli altri.

A differenza di altri principi, che connettono l'astrazione teorica al mondo fisico, per natura stessa della meccanica statistica questi connettono due branche della teoria, quella microscopica e quella macroscopica, per cui è possibile che queste assunzioni siano false a livello formale per alcune classi di sistemi. Questo è il caso dei sistemi \textit{integrabili} (e quindi \textit{non ergodici}) in meccanica classica, ed è il caso di quasi tutti i sistemi quantistici (in cui la situazione è molto più sottile).

\'E sufficiente però considerare che questi sistemi sono pochi nel caso classico, mentre nel caso quantistico il problema si aggira in un altro modo, per cui i principi considerati consentono la descrizione di una classe enorme di sistemi (la quasi totalità).

\subsection{Entropia}
\label{sec:entro}

Si supponga che il sistema abbia $\Gamma$ possibili microstati, con $\Gamma \equiv \Gamma(E,N,V)$, cioè una funzione del volume, dell'energia e del numero totale dei componenti (d'ora in avanti \textit{particelle}) del sistema.

\begin{defn}[Entropia, microscopica]
	L'\textit{entropia} di un sistema è definita in base alle proprietà microscopiche di un sistema come:
	\begin{equation*}
	S = k \log\Gamma
	\end{equation*}
\end{defn}

In questo modo anche l'entropia è una funzione di volume, energia e numero di particelle del sistema $S \equiv S(E,N,V)$.

Invertendo l'entropia come funzione dell'energia si ottiene $E(S,N,V)$, e da questa espressione si possono studiare le variazioni dell'energia totale.

\begin{equation*}
	\dd E = \left(\frac{\partial E}{\partial S}\right)_{N,V} \dd S + \left(\frac{\partial E}{\partial V}\right)_{S,N} \dd V + \left(\frac{\partial E}{\partial N}\right)_{S,V} \dd N
\end{equation*}

\begin{note}[Invertibilità di $S(E,N,V)$]
	\'E sempre possibile invertire l'entropia in funzione dell'energia a $V$ e $N$ fissati, infatti se non c'è un limite superiore per l'energia di singola particella il numero di microstati sarà una funzione crescente dell'energia, e quindi anche l'entropia.
\end{note}

\paragraph{Osservabili intensive} Le osservabili estensive caratteristiche di un sistema macroscopico $E, N, V$ sono state definite in modo naturale a partire dalle caratteristiche microscopiche.

A questo punto si possono definire le osservabili intensive dalle variazioni dell'energia, distinguendo le varie sorgenti.

\begin{defn}[Osservabili Intensive]
	\label{def:ossint}
	Si definisce \textit{temperatura:}
	\begin{equation*}
	T = \left(\frac{\partial E}{\partial S}\right)_{N,V}
	\end{equation*}
	
	Si definisce \textit{pressione:}
	\begin{equation*}
	P = - \left(\frac{\partial E}{\partial V}\right)_{S,N}
	\end{equation*}
	
	Si definisce \textit{potenziale chimico:}
	\begin{equation*}
	\mu = \left(\frac{\partial E}{\partial N}\right)_{S,V}
	\end{equation*}
\end{defn}

Le definizioni che si sono date sono del tutto \textit{formali}, a priori senza alcun senso fisico alle spalle. Si esamina quindi una di queste (la temperatura) per capire la corrispondenza della definizione a un concetto fisico.

\paragraph{Temperatura} Il concetto fisico di temperatura è dato dal \textit{principio zero} della termodinamica: essa è una caratteristica del sistema che ne descrive l'equilibrio termico rispetto ad altri sistemi. La temperatura è quindi un numero reale:
\begin{itemize}
	\item condiviso per sistemi fra loro all'equilibrio;
	\item per sistemi non in equilibrio indica il verso in cui fluisce il calore.
\end{itemize}

Quando due sistemi, con numero di microstati $\Gamma_1$ e $\Gamma_2$, sono separati, il numero di microstati totale sarà $\Gamma_1\Gamma_2$.
Quando i sistemi sono posti in contatto, a $V$ e $N$ fissati per ciascuno, tutto ciò che può succedere macroscopicamente è che una parte dell'energia di uno fluisca nell'altro, e per la monotonicità dell'entropia quindi se aumenta $S_1$ allora diminuirà $S_2$ e viceversa.

Se i sistemi sono all'equilibrio l'entropia totale è allora in un massimo, altrimenti aumenterebbe tramite scambio di energia. Inoltre anche l'energia totale è conservata, per cui:

\begin{align*}
&\begin{rcases*}
\delta(E_1 + E_2) = 0 \\
\delta E_i = T_i \delta S_i
\end{rcases*}
\implies T_1 \delta S_1 + T_2 \delta S_2 = 0 \\
&\delta(S_1 + S_2) = 0
\end{align*}

\noindent Da cui si ottiene facilmente $T_1 = T_2$.

Si può verificare anche l'affermazione sul verso del flusso di energia (calore): sia $T_1 < T_2$, l'energia è sempre conservata, inoltre si considera che l'entropia totale può solo aumentare:

\begin{align*}
&\begin{rcases*}
\delta(E_1 + E_2) = 0 \\
\delta E_i = T_i \delta S_i
\end{rcases*}
\implies T_1 \delta S_1 + T_2 \delta S_2 = 0 \implies \implies \delta S_1 = - \frac{T_2}{T_1} \delta S_2\\
& \delta(S_1 + S_2) \geq 0 \implies \delta S_1 \geq - \delta S_2
\end{align*}

Da cui si ottiene:

\begin{equation*}
- \frac{T_2}{T_1} \delta S_2 \geq - \delta S_2 \implies (1 - \frac{T_2}{T_1}) \delta S_2 \geq 0 \implies \delta S_2 \leq 0
\end{equation*}

E per la monotonicità dell'entropia si ha anche $\delta E_2 \leq 0$, che corrisponde a quanto atteso.

\paragraph{Equazione di stato} A questo punto si è in grado di calcolare, astrattamente, l'\textit{l'equazione di stato}, eliminando l'entropia dalle due equazioni:

\begin{align*}
	&T(S,V,N) = \left(\frac{\partial E}{\partial S}\right)_{N,V} \\
	&P(S,V,N) = - \left(\frac{\partial E}{\partial V}\right)_{S,N}
\end{align*}

\subsection{Precisazioni teoriche sui fondamenti}
\label{sec:teorpipterm}
Anche se le temperatura di due sistemi è la stessa l'operazione di metterli a contatto non è senza conseguenze: si perde traccia dell'energia esatta di ognuno dei due sistemi, mantenendo l'informazione su quella totale.

Per cui si pongono due questioni:
\begin{itemize}
	\item quanta incertezza viene introdotta?
	\item negli argomenti usati precedentemente nello studio della temperatura, funziona tutto bene anche avendo perso traccia delle singole energie nel contatto termico?
\end{itemize}

La risposta alla prima domanda è: sostanzialmente poca, ed è per questo che la meccanica statistica funziona bene (si veda la \cref{sec:fluct}, per una trattazione più estesa).

La risposta alla seconda domanda è che non ci serve sapere quantitativamente l'energia, ma che è sufficiente sapere che il sistema è isolato e la sua energia è fissata.
\newline

C'è un punto ancora più sottile: oltre all'incertezza termodinamica sull'energia, se consentiamo le transizioni fra microstati a livello quantistico non siamo in uno stato stazionario, ma in stati con tempo di vita finito, e quindi vi è un'incertezza del tutto quantistica sulla loro energia.

Comunque se il numero di particelle è abbastanza grande questa incertezza non è rilevante: $\Gamma \sim 10^N$, per cui se anche l'errore sul conteggio degli stati fosse dell'ordine di $ N $ l'errore sul logaritmo (cioè sull'entropia) diventa irrisorio per grandi $ N $.

\paragraph{Descrizione canonica} Si può però rinunciare alla descrizione \textit{microcanonica} (energia fissata, vedi \cref{sec:statmech}) e decidere di considerare un piccolo sottosistema di un grande sistema isolato: per esso non sarà fissata l'energia, ma la temperatura, attraverso il contatto col resto del sistema che fungerà da \textit{bagno termico}.

L'energia del sistema quindi sarà libera di fluttuare, ma la descrizione si sposterà sulla \textit{densità di stati}, che non è soggetta a incertezza quantistica.

\begin{note}[Legge di dispersione]
	La \textit{densità di stati} tipicamente è determinata dal seguente procedimento:
	\begin{itemize}
		\item si assume che sia piatta sullo spazio delle fasi accessibile;
		\item si trasforma in una funzione dell'energia, una volta nota l'energia come funzione degli impulsi e delle poszioni.
	\end{itemize}
	Quest'ultima è a volte nota come \textit{legge di dispersione}.
\end{note}

\subparagraph{Fluttuazioni} \`E importante distinguere fra due tipi di fluttuazioni:
\begin{description}
	\item[fluttuazioni microscopiche:] si è detto che un sistema in equilibrio esplora tutti i microstati accessibili \textit{ergodicamente}, ma questo tipo di fluttuazioni fra microstati non sono fluttuazioni dell'equilibrio: l'equilibrio ha origine proprio da una media su queste transizioni;
	\item[fluttuazioni macroscopiche:] quando si è introdotto l'approccio \textit{canonico} si è inserita la possibilità che l'energia non fosse fissata, ma fluttuasse; queste fluttuazioni sono di tipo macroscopico, perché al livello microscopico descritto prima tanto il microcanonico quanto il canonico fluttuano.
\end{description}

% quest'ultima parte sulle fluttuazioni va rivista graficamente e dal punto di vista dell'italiano.

\section{Termodinamica}
\label{sec:termod}


\subsection{I principi della termodinamica}
La \textit{termodinamica} è fondamentalmente un sistema logico basato su quattro assiomi.

\paragraph{Principio zero} Il principio zero è stato già citato e discusso nella \cref{sec:teorpipterm}, esso caratterizza la relazione di equilibrio termico fra sistemi. Si riporta lo stesso un enunciato conciso:

\begin{defn}[Principio zero della termodinamica]
	La relazione di equilibrio termico è transitivi, quindi è una relazione di equivalenza.
	
	Più esplicitamente: se A è in equilibrio con B e con C, allora B è in equilibrio con C.
\end{defn}

\begin{note}
	C'è da fare attenzione anche in questo caso all'applicabilità fisica di questo principio: la verifica dell'equilbrio termico è effettuata mediante contatto termico, per cui per stabilire che due corpi non sono in equilibrio è necessario veder fluire calore.
	
	Se il calore che fluisce non è poco due corpi non in equilibrio potrebbero diventarlo. Cioè: la verifica dell'equilibrio fra due corpi può alterare la situazione iniziale, anzi, in generale \textbf{deve} farlo.
	
	Per aggirare questo problema ci si può servire di corpi sufficientemente piccoli di test (detti \textit{termometri}) che possono mediare il processo di verifica della situazione di equilibrio senza alterare apprezzabilmente lo stato dei corpi da testare, ed è in questo senso che va inteso il principio zero.
\end{note}

\paragraph{Primo principio} Il primo principio asserisce la \textit{conservazione dell'energia}: esso, macroscopicamente, corrisponde all'istituzione stessa di una quantità, detta energia, che si conservi in sistemi isolati.

\begin{defn}[Primo principio della termodinamica]
	L'energia è una quantità conservata per sistemi isolati.
	
	Più esplicitamente: se l'energia interna a un sottosistema del sistema isolato globale (da qui in poi detto \textit{universo}) non è conservata, essa è stata scambiata con altre parti dell'universo. Lo scambio di energia può assumere due forme: lavoro meccanico o calore.
	
	\begin{equation*}
		\dd E = \dd Q + \dd W
	\end{equation*}
	
	$Q$ è il calore assorbito dal sottosistema, mentre $W$ è il lavoro fatto sul sottosistema.
\end{defn}

\noindent Si noti che il lavoro meccanico corrisponde ad un trasporto di energia \textit{macroscopico}, mentre il calore è essenzialmente un trasporto di energia \textit{microscopico}. Questa è la principale differenza tra i due.

Per il \textit{gas perfetto} si può legare il lavoro alla variazione delle osservabili macroscopiche:

\begin{equation*}
\dd W = \mathcal{F} \dd x = \frac{\mathcal{F}}{A} (A\dd x) = - P \dd V
\end{equation*}

\noindent In generale è possibile identificare il lavoro, nell'ambito della meccanica lagrangiana, fermandosi alla prima uguaglianza e considerando come $\dd x$ gli spostamenti generalizzati e com $ \mathcal{F} $ le forze generalizzate corrispondenti (bisognerà inoltre sommare su tutti i possibili contributi).
\newline

Si ottiene quindi che:
\begin{equation*}
	\left(\frac{\partial E}{\partial V}\right)_Q = - P
\end{equation*}

\noindent Che può essere confrontato con la definizione data nella \cref{sec:entro}.

Questo è legato al fatto che una trasformazione \textit{isoentropica} avviene senza scambio di calore, infatti variando in modo sufficientemente lento il volume per il \textit{teorema adiabatico} i microstati cambieranno, ma ci sarà una corrispondenza uno a uno fra vecchi e nuovi, quindi il loro numero è fissato.

Queste ultime affermazioni in realtà sono tutte nell'ottica della meccanica statistica, perché a livello termodinamico l'entropia è definita nell'ambito del \textit{secondo principio}, che non è stato ancora esposto.

\paragraph{Secondo principio} Il secondo principio è enunciato nel modo più termodinamicamente corretto nelle forme di \textit{Kelvin} e di \textit{Clausius}, ben note e reperibili. Esse consentono la dimostrazione del teorema di \textit{Carnot}, e conseguentemente di quello di \textit{Clausius}, che consente di definire l'entropia.

Si sceglie allora di assumere noto il teorema di \textit{Clausius}, definendo l'entropia, e servendosi di essa per enunciare il secondo principio, ma deve essere noto che questo non è realmente possibile in termodinamica, in quanto il secondo principio è logicamente precedente alla definizione stessa di entropia.

\begin{defn}[Entropia]
	La variazione di entropia fra uno stato A e uno stato B è:
	\begin{equation*}
	\Delta S = \int_{A \rightarrow B} \frac{\dd Q}{T}
	\end{equation*}
	dove l'integrazione è effettuata su un cammino costituito da una trasformazione \textit{reversibile}.
	
	L'entropia è quindi definita così a meno di una costante, che fissa il valore dell'entropia per un certo stato.
\end{defn}

\noindent E dunque:

\begin{defn}[Secondo principio della termodinamica]
	L'entropia di un sistema isolato fuori equilibrio tende ad aumentare.
\end{defn}

\noindent Gli stati di equilibrio sono quindi caratterizzati come massimi dell'entropia.

\paragraph{Terzo principio} Il terzo principio si colloca ai margini della termodinamica, e più che farne parte ne specifica i limiti. Infatti esso afferma che:

\begin{defn}[Terzo principio della termodinamica]
	L'entropia a temperatura nulla (zero assoluto) è nulla.
\end{defn}

\noindent che in modo equivalente può essere inteso come: \textit{la temperatura nulla non è raggiungibile da processi termodinamici.}

\subsection{Grandezze termodinamiche}
\label{sec:thermquant}

Vi sono quattro variabili termodinamiche principali, non indipendenti:

\begin{equation*}
\begin{matrix}
S	&	V \\
T	&	P \\
\end{matrix}
\end{equation*}

\noindent Organizzate nel modo seguente:
\begin{itemize}
	\item la prima riga sono estensive;
	\item la seconda riga intensive;
	\item le variabili appartenenti alla stessa colonna sono coniugate.
\end{itemize}

\noindent Le variabili coniugate compaiono a coppie nell'espressione dell'energia. Ogni variabile termodinamica può essere espressa come funzione della variabile coniugata e di una delle altre due (si verifica a partire dalle espressioni date nella \cref{def:ossint}).

Perciò è sempre possibile scegliere una coppia di variabili, non coniugate, come \textit{indipendenti}, le altre due saranno quindi \textit{dipendenti} e ottenibili come funzioni delle prime.
\newline

Le variabili termodinamiche scelte come \textit{dipendenti} possono essere ricavate da un singolo \textit{potenziale termodinamico}, se le variabili indipendenti scelte sono le variabili \textit{proprie} del potenziale.

I potenziali termodinamici sono ottenuti come opportune trasformate di Legendre dell'energia, si passa quindi ad illustrarli.

\paragraph{Energia E} Le sue variabili proprie sono $S$ e $V$. L'espressione del suo differenziale è:

\begin{equation*}
\dd E = T \dd S - P \dd V
\end{equation*}

\paragraph{Energia libera F} Le sue variabili proprie sono $T$ e $V$. La sua espressione in funzione dell'energia $E$ è:

\begin{equation*}
F = E - T S
\end{equation*}

E dunque l'espressione del suo differenziale è:

\begin{equation*}
\dd F = - S \dd T - P \dd V
\end{equation*}

\begin{note}
	Le variabili proprie dell'energia libera sono particolarmente comode (il motivo è per lo più che non contengono l'entropia), per cui essa è decisamente utile ai fini del calcolo dell'equazione di stato, cioè $ P(V,T) $ (un altro motivo è che si esprime in modo semplice in termini della \textit{funzione di partizione}, vedi \cref{sec:stmechintro}).
\end{note}

\paragraph{Energia libera di Gibbs G }Le sue variabili proprie sono $T$ e $P$. La sua espressione in funzione dell'energia $E$ è:

\begin{equation*}
G = E - T S + P V
\end{equation*}

E dunque l'espressione del suo differenziale è:

\begin{equation*}
\dd G = - S \dd T + V \dd P
\end{equation*}

\begin{note}
	Anche questo potenziale ha una sua utilità specifica: esso è espresso in funzione delle variabili \textit{intensive}, questo lo rende particolarmente per caratterizzare alcune situazioni (es: \textit{transizioni di fase}).
\end{note}


\paragraph{Entalpia H}Le sue variabili proprie sono $S$ e $P$. La sua espressione in funzione dell'energia $E$ è:

\begin{equation*}
H = E + P V
\end{equation*}

E dunque l'espressione del suo differenziale è:

\begin{equation*}
\dd H = T \dd S + V \dd P
\end{equation*}

Si nota che l'entalpia ha una proprietà per cui in inglese è chiamata anche \textit{heat function}, ed è:

\begin{equation*}
\dd H)_P = T \dd S)_P = \dd Q)_p
\end{equation*}

\subsubsection{Relazioni di Maxwell}
Applicando il \textit{teorema di Schwarz} (di cui supponiamo sempre verificate le ipotesi, lontano da punti critici) si ha la commutazione delle derivate seconde, e applicando questo risultato ai vari potenziali termodinamici si ottengono le cosiddette \textit{relazioni di Maxwell}.

Si riporta solo il caso dell'energia libera a titolo di esempio:

\begin{equation*}
\left(\frac{\partial P}{\partial T}\right)_V = \frac{\partial}{\partial T} \left(- \left(\frac{\partial F}{\partial V}\right)_T\right)_V = \frac{\partial}{\partial V} \left(- \left(\frac{\partial F}{\partial T}\right)_V\right)_T = \left(\frac{\partial S}{\partial V}\right)_T
\end{equation*}

\`E noto un diagramma che riassume le proprietà dei potenziali termodinamici, cioè le variabili proprie e le relazioni di Maxwell, ed è considerato un utile strumento mnemonico (\cref{fig:maxrel}).

\begin{figure}[t]
	\centering
	\input{MaxRel.pdf_tex}
	\caption{Diagramma illustrativo delle relazioni fra potenziali termodinamici (noto anche come \textit{diagramma di koenig} )}
	\label{fig:maxrel}
\end{figure}

\subsubsection{Numero di particelle}
Fino ad adesso si è considerato costante il numero di particelle, ma in base alla scelta che si fa del sottosistema anche esso può essere variabile: non è necessario che un sottosistema sia identificato dalla scelta di alcune particelle, che in generale è impossibile da effettuare (vedi \cref{secidpart}), ma potrebbe essere descritto da altre proprietà (es: il volume che occupa, un certo insieme di stati, \dots).

Perciò, coerentemente con la \cref{def:ossint}, si può scrivere:

\begin{equation*}
\dd E = T \dd S - P \dd V + \mu \dd N
\end{equation*}

\noindent Da questa inoltre risultano le espressioni degli altri potenziali termodinamici, ottenute differenziando le opportune trasformate di Legendre.

\begin{note}
	Un'importante osservazione è che le variazioni dei potenziali termodinamici rispetto a qualunque nuova osservabile, tenendo costanti le variabili proprie, sono tutte uguali, infatti:
	
	\begin{equation*}
	\mu \delta N = (\delta E)_{S, V} = (\delta F)_{T,V} = (\delta G)_{T,P} = (\delta H)_{S,P}
	\end{equation*}
\end{note}

Inoltre si noti che $E$ è una grandezza estensiva, le cui variabili proprie sono anch'esse estensive; sfruttando questa proprietà si ha che scalando di una quantià $\lambda$ il sistema\footnote{Si immagini di frazionare in parti il sistema, se il sistema è sufficientemente grande posso coprire tutto $\mathbb{Q}^+$, e passando al limite $\mathbb{R}^+$.}:

\begin{align*}
& \dd (\lambda E) = T \dd (\lambda S) - P \dd (\lambda V) + \mu \dd (\lambda N) \implies\\ 
& \qquad \implies E \dd \lambda + \lambda \dd E  = T (S \dd \lambda + \lambda \dd S) - P (V \dd \lambda + \lambda \dd V) + \mu (N\dd \lambda + \lambda \dd N)
\end{align*}

Raccogliendo $\lambda$ e $\dd lambda$, e considerando che poiché $\lambda$ è arbitrario le due identità risultanti devono essere soddisfatte separatamente, si ottiene l'equazione di Eulero:

\begin{equation*}
E = TS - PV + \mu N
\end{equation*}

Da cui si ottiene l'espressione per la variazione del potenziale chimico:

\begin{equation*}
\dd \mu = - \frac{S}{N} \dd T + \frac{V}{N} \dd P
\end{equation*}

L'equazione di Eulero per l'energia implica che anche gli altri potenziali termodinamici possano avere una forma simile. In particolare:

\begin{equation*}
G = \mu N
\end{equation*}

\paragraph{Gran Potenziale $\Omega$} Si può definire un ulteriore potenziale termodinamico, invertendo le nuove variabili $N \rightarrow \mu$. Le sue variabili proprie sono $T$, $V$ e $\mu$. La sua espressione in funzione dell'energia $E$ è:

\begin{equation*}
\Omega = F - \mu N = E - TS - \mu N
\end{equation*}

E dunque l'espressione del suo differenziale è:

\begin{equation*}
\dd \Omega = - S \dd T - P \dd V - N \dd \mu
\end{equation*}

Dall'equazione di Eulero si ricava:

\begin{equation*}
\Omega = - P V
\end{equation*}

\subsection{Variabili Magnetiche}
Lo studio del magnetismo in termodinamica è frequente, e la definizione di variabili magnetiche non è affatto dissimile dall'introduzione di pressione e volume per il gas perfetto come forza e spostamento \textit{generalizzati}.

Si nota solo che il ruolo di forza generalizzata in questo ambito è svolto dal campo magnetico $ H $, mentre lo spostamento generalizzato è $ \dd (M V) $ dove $M$ è la magnetizzazione del mezzo e $V$ è ancora il volume.

\subsection{Principio variazionale}
Il principio variazionale fondamentale in termodinamica è quello fissato dal \textit{secondo principio}: l'entropia per uno stato di equilibrio è massima.

Questo si riflette in una serie di principi variazionali ausiliari, dettati dalla possibilità di raggiungere l'equilibrio tenendo costanti alcune delle variabili termodinamiche.

\begin{align*}
	T, V, N = cost. \qquad \implies \qquad F = \text{minimum}\\
	T, P, N = cost. \qquad \implies \qquad G = \text{minimum}\\
	T, V, \mu = cost. \qquad \implies \qquad \Omega = \text{minimum}\\
\end{align*}

Si posson ottenere considerando il sottosistema che fluttua alla ricerca dell'equilibrio e il bagno termico, il cui stato di equilibrio non è influenzato dalle fluttuazioni del sottosistema. Perciò si ha:

\begin{equation*}
\begin{rcases*}
\begin{rcases*}
\dd E' = T \dd S' - \dd W'\\
\delta (E + E') = 0
\end{rcases*} \dd E + T \dd S' - \dd W' = 0\\
\delta (S + S') \geq 0
\end{rcases*}
\delta E \leq T \delta S + p \delta V
\end{equation*}

Dall'ultima espressione si ottiene facilmente l'enunciato per $F$, ponendo $\delta V = 0$ e $T \delta S = \delta (T S)$. Analogamente si può fare per gli altri due casi.

\subsection{Derivate termodinamiche}

Si è visto nella \cref{sec:thermquant} come le variabili termodinamiche possano essere ottenute come derivate prime dei potenziali termodinamici, che costituisce la prima definizione data di alcune di esse (\cref{def:ossint}).

Si consideri d'ora in avanti i potenziali termodinamici come le quantità termodinamiche \textit{massimamente integrate}, le altre grandezze termodinamiche saranno caratterizzate dall'essere ottenute a un qualche ordine di derivazione da esse.

Perciò, se le variabili stesse costituiscono il \textit{primo ordine di derivazione}, si prenderà in esame adesso il \textit{secondo ordine di derivazione}. Si è già parlato di esso nella \cref{sec:thermquant}, a proposito delle \textit{relazioni di Maxwell}; in quell'ambito si sono considerate solo le derivate seconde miste, passiamo quindi a considerare le altre.

\begin{defn}[Capacità termica]
	Si definisce \textit{capacità termica a volume costante} la quantità $C_V$:
	\begin{equation*}
	C_V = T \left(\frac{\partial S}{\partial T}\right)_V
	\end{equation*}
	Si definisce \textit{capacità termica a pressione costante} la quantità $C_P$:
	\begin{equation*}
	C_P = T \left(\frac{\partial S}{\partial T}\right)_P
	\end{equation*}
\end{defn}

\noindent La capacità termica quantifica la variazione di temperatura $\delta T$ in base allo scambio di calore $T \delta S$.

Per la capacità termica $C_V$ si nota la relazione:
\begin{equation*}
C_V = \left(\frac{\partial E}{\partial T}\right)_V
\end{equation*}

\noindent è però importante rendersi conto che la temperatura $T$ non è una delle variabili proprie dell'energia.

Per entrambe le capacità termiche si può esprimere però propriamente in funzione dei potenziali termodinamici con le variabili proprie adeguate:

\begin{align*}
C_V = T \left(\frac{\partial^2 F}{\partial T^2}\right)_V\\
C_P = T \left(\frac{\partial^2 G}{\partial T^2}\right)_P
\end{align*}

\noindent che giustifica il fatto che esse siano grandezze del \textit{secondo ordine} (d'ora in poi è omesso che si tratti di derivate).
\newline

Analogamente si possono definire le compressibilità:


\section{Meccanica Statistica}
\label{sec:statmech}

\subsection{Introduzione}
\label{sec:stmechintro}

\subsection{Particelle identiche}
\label{sec:idpart}

\subsection{Fluttuazioni}
\label{sec:fluct}